<!doctype html>
<html lang="zh" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-v1.0.0 docs-doc-page docs-doc-id-case-study/weibo-case-study" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.1">
<title data-rh="true">Weibo&#x27;s Case Study | Fluid</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://fluid-cloudnative.github.io/zh/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://fluid-cloudnative.github.io/zh/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://fluid-cloudnative.github.io/zh/docs/case-study/weibo-case-study"><meta data-rh="true" property="og:locale" content="zh"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" name="docusaurus_locale" content="zh"><meta data-rh="true" name="docsearch:language" content="zh"><meta data-rh="true" name="docusaurus_version" content="v1.0.0"><meta data-rh="true" name="docusaurus_tag" content="docs-default-v1.0.0"><meta data-rh="true" name="docsearch:version" content="v1.0.0"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-v1.0.0"><meta data-rh="true" property="og:title" content="Weibo&#x27;s Case Study | Fluid"><meta data-rh="true" name="description" content="This article introduces a new architecture solution based on Fluid (containing JindoRuntime) designed and implemented by Weibo&#x27;s technical teams."><meta data-rh="true" property="og:description" content="This article introduces a new architecture solution based on Fluid (containing JindoRuntime) designed and implemented by Weibo&#x27;s technical teams."><link data-rh="true" rel="icon" href="/zh/img/fluid-icon-color.png"><link data-rh="true" rel="canonical" href="https://fluid-cloudnative.github.io/zh/docs/case-study/weibo-case-study"><link data-rh="true" rel="alternate" href="https://fluid-cloudnative.github.io/docs/case-study/weibo-case-study" hreflang="en"><link data-rh="true" rel="alternate" href="https://fluid-cloudnative.github.io/zh/docs/case-study/weibo-case-study" hreflang="zh"><link data-rh="true" rel="alternate" href="https://fluid-cloudnative.github.io/docs/case-study/weibo-case-study" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://LFPGLLH528-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/zh/blog/rss.xml" title="Fluid RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/zh/blog/atom.xml" title="Fluid Atom Feed">



<link rel="search" type="application/opensearchdescription+xml" title="Fluid" href="/zh/opensearch.xml"><link rel="stylesheet" href="/zh/assets/css/styles.8e3a1f9d.css">
<script src="/zh/assets/js/runtime~main.8efdc8ce.js" defer="defer"></script>
<script src="/zh/assets/js/main.0cbb1e2e.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="跳到主要内容"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">跳到主要内容</a></div><nav aria-label="主导航" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="切换导航栏" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/zh/"><div class="navbar__logo"><img src="/zh/img/fluid-horizontal-color.png" alt="" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/zh/img/fluid-horizontal-white.png" alt="" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/zh/docs">文档</a><a class="navbar__item navbar__link" href="/zh/blog">博客</a><a class="navbar__item navbar__link" sidebarid="communitySidebar" href="/zh/community/meeting_schedule">社区</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a aria-current="page" class="navbar__link active" aria-haspopup="true" aria-expanded="false" role="button" href="/zh/docs">v1.0.0</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/zh/docs/next/case-study/weibo-case-study">Latest</a></li><li><a aria-current="page" class="dropdown__link dropdown__link--active" href="/zh/docs/case-study/weibo-case-study">v1.0.0</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>简体中文</a><ul class="dropdown__menu"><li><a href="/docs/case-study/weibo-case-study" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/zh/docs/case-study/weibo-case-study" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="zh">简体中文</a></li></ul></div><a href="https://github.com/fluid-cloudnative/fluid" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="切换浅色/暗黑模式（当前为浅色模式）" aria-label="切换浅色/暗黑模式（当前为浅色模式）" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="搜索"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">搜索</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="回到顶部" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="文档侧边栏" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/zh/docs">Core Concepts</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/zh/docs/get-started/quick-start">Get Started</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/zh/docs/demos/demo-accelerate-remote-file-accessing-with-fluid">Demos</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/zh/docs/tutorials/dataset-creation/accelerate-data-accessing-posix">Tutorials</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/zh/docs/operation-guide/runtime-monitoring">Operation Guide</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/zh/docs/developer-guide/how-to-develop">Developer Guide</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/zh/docs/case-study/alibaba-case-study">Case Study</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/zh/docs/case-study/alibaba-case-study">Alibaba&#x27;s Case Study</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/zh/docs/case-study/weibo-case-study">Weibo&#x27;s Case Study</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/zh/docs/case-study/metabit-trading-case-study">Metabit Trading&#x27;s Case Study</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/zh/docs/case-study/haomo-case-study">HAOMO&#x27;s Case Study</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/zh/docs/case-study/zuoyebang-case-study">Zuoyebang&#x27;s Case Study</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/zh/docs/troubleshooting-and-faq/troubleshooting">Troubleshooting and FAQ</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/zh/docs/release-and-API-doc/release">Release and API Doc</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="页面路径"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="主页面" class="breadcrumbs__link" href="/zh/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Case Study</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Weibo&#x27;s Case Study</span><meta itemprop="position" content="2"></li></ul></nav><span class="theme-doc-version-badge badge badge--secondary">版本：v1.0.0</span><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">本页总览</button></div><div class="theme-doc-markdown markdown"><h1>Weibo&#x27;s Case Study</h1>
<blockquote>
<p>This article introduces a new architecture solution based on Fluid (containing JindoRuntime) designed and implemented by Weibo&#x27;s technical teams.</p>
</blockquote>
<p><em>By Wu Tong and Hao Li, Engineers of Weibo Deep Learning Platform</em></p>
<p>The deep learning platform plays an important role in Weibo&#x27;s social business. Under the architecture where computing and storage are separated, there is a problem of low performance in data access and scheduling in Weibo&#x27;s deep learning platform. This article introduces a new architecture solution based on Fluid (containing JindoRuntime) designed and implemented by Weibo&#x27;s technical teams. It significantly improves the performance and stability of training the model for massive small files. The distributed training scenarios with multiple nodes and GPUs can accelerate model training by 18 times.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-background">1. Background<a href="#1-background" class="hash-link" aria-label="1. Background的直接链接" title="1. Background的直接链接">​</a></h2>
<p>Sina Weibo is the largest social media platform in China. Every day, hundreds of millions of pieces of content are generated and spread on it. The following figure shows the business ecosystem of Weibo. Quality content producers generate and spread premium content. Other users can enjoy this content and follow the microbloggers they like. Thus, interaction is established, and a sound closed-loop ecosystem is formed.</p>
<p><img decoding="async" loading="lazy" alt="background" src="/zh/assets/images/weibo-background-d621e12534b177a7697b37dce2037711.png" width="1002" height="695" class="img_ev3q"></p>
<p>The main function of Weibo&#x27;s machine learning platform is to make the whole process operate more efficiently and smoothly. With an understanding of the quality content, the platform builds the user profiles and pushes the content that interests users. This allows users to interact with the content producers and encourages producers to produce more (and better) content. As a result, a win-win situation for both information consumers and producers is created. As multimedia content becomes mainstream, deep learning technology becomes more important. From the understanding of multimedia content to the optimization of CTR tasks, the support of deep learning technology is indispensable.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-challenges-of-training-large-scale-deep-learning-models">2. Challenges of Training Large-Scale Deep Learning Models<a href="#2-challenges-of-training-large-scale-deep-learning-models" class="hash-link" aria-label="2. Challenges of Training Large-Scale Deep Learning Models的直接链接" title="2. Challenges of Training Large-Scale Deep Learning Models的直接链接">​</a></h2>
<p>With the widespread use of deep learning in Weibo&#x27;s business scenarios, its deep learning platform plays a central role. The platform decouples computing resources from storage resources by separating storage and computing. Thus, it provides flexible resource allocation, realizes convenient storage expansion, and reduces storage costs.</p>
<p><img decoding="async" loading="lazy" alt="challenge" src="/zh/assets/images/weibo-challenge-7d01a4ec8c680141c1233c442e916e5e.png" width="1080" height="760" class="img_ev3q"></p>
<p>However, this architecture also brings some challenges, among which the most critical ones are data access performance and stability.</p>
<ol>
<li>
<p><strong>The separation of computation and storage leads to high latency in data access and slows down training.</strong> Deep learning tasks (image or speech models) used by the business team will access massive small files. Tests have shown that the performance of HDFS reading a large number of small files differs from local reading by 10-100 times.</p>
</li>
<li>
<p><strong>Kubernetes scheduler is not aware of data cache, and accessing the same data source after running multiple times is still very slow.</strong> Some deep learning tasks access the same data repeatedly at runtime, which includes tasks with the same model but different hyperparameters, tasks with fine-tuning model and the same input, and tasks of AutoML. They generate reusable data cache. However, the native Kubernetes scheduler is not cache-aware. Therefore, the result of application scheduling is not good, the cache cannot be reused, and the performance cannot be improved.</p>
</li>
<li>
<p><strong>Most deep learning frameworks lack support for HDFS interfaces, making the development difficult.</strong> Frameworks such as PyTorch and MxNet only support POSIX interfaces, and HDFS interfaces require additional development for adaptation. Therefore, it is necessary to support the POSIX interface in the model development phase and the HDFS interface in the model training phase. As a result, we need to introduce model code to adapt to the complexity of different storage.</p>
</li>
<li>
<p><strong>HDFS becomes a bottleneck for concurrent data access, bringing challenges to stability.</strong> Hundreds of GPU machines on Weibo&#x27;s machine learning platform will access HDFS clusters concurrently during simultaneous training. At the same time, the I/O pressure of deep learning training is relatively high. HDFS service becomes a single point of performance, which poses a huge challenge to the performance and stability of HDFS. Once a task slows down the HDFS system, other training tasks will also be affected. Moreover, once HDFS fails, the entire training cluster will also be affected.</p>
</li>
</ol>
<p>Through the monitoring and analysis of Weibo&#x27;s machine learning platform, we found that due to the limitation of I/O performance, expensive computing resources such as GPU cannot be fully utilized. In addition, the resource usage of memory and local hard disk in the cluster is very low as most of the space is unused and stable. This happens because most deep learning tasks do not use local disks, and the memory usage is not high. Therefore, we believe that it is a better solution if the memory and disk resources of the cluster can be fully utilized to speed up data access.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-fluid--jindoruntime-provide-efficient-support-for-weibos-machine-learning-platform">3. Fluid + JindoRuntime Provide Efficient Support for Weibo&#x27;s Machine Learning Platform<a href="#3-fluid--jindoruntime-provide-efficient-support-for-weibos-machine-learning-platform" class="hash-link" aria-label="3. Fluid + JindoRuntime Provide Efficient Support for Weibo&#x27;s Machine Learning Platform的直接链接" title="3. Fluid + JindoRuntime Provide Efficient Support for Weibo&#x27;s Machine Learning Platform的直接链接">​</a></h2>
<p>We need to achieve better data locality to meet the computational requirements of large-scale deep learning model training. We want to achieve the following goals:</p>
<ol>
<li>
<p>Computation can take full advantage of localization to access data, so data does not need to be read repeatedly via the network. This will speed up the training of deep learning model and increase the GPU usage of cluster.</p>
</li>
<li>
<p>The load pressure on HDFS can be reduced. The latency of data access can be reduced, and the availability of HDFS can be improved by reading part of the data locally.</p>
</li>
<li>
<p>The advantages of cache nodes for hot data sets can be maximized. Therefore, they can intelligently schedule tasks to data cache nodes without user perception. Finally, common model training programs can be faster.</p>
</li>
<li>
<p>Data can be read through the POSIX interface. This eliminates the need to use different data access interfaces during the model development and training phases. Consequently, the cost of developing deep learning model programs is reduced.</p>
</li>
</ol>
<p>We are eager to find software with distributed cache acceleration capabilities on Kubernetes to achieve these goals. Fortunately, we found Fluid, a CNCF Sandbox project that met our demands. Therefore, we have designed a new architecture scheme based on Fluid. After verification and comparison, we chose JindoRuntime as the acceleration run time.</p>
<p><img decoding="async" loading="lazy" alt="fluid" src="/zh/assets/images/weibo-fluid-a214850a99a7b1f8df6c23b525b8cc7b.png" width="1080" height="585" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="31-an-introduction-to-architecture-components">3.1 An Introduction to Architecture Components<a href="#31-an-introduction-to-architecture-components" class="hash-link" aria-label="3.1 An Introduction to Architecture Components的直接链接" title="3.1 An Introduction to Architecture Components的直接链接">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="311-fluid">3.1.1 Fluid<a href="#311-fluid" class="hash-link" aria-label="3.1.1 Fluid的直接链接" title="3.1.1 Fluid的直接链接">​</a></h4>
<p>Fluid [1] is an extensible distributed data orchestration and acceleration system running on Kubernetes. It orchestrates data and schedules the applications that use data. As solves the pain points that the cloud-native orchestration framework faces when running such applications, such as the high latency of data access, the difficulty in the joint analysis of multiple data sources, and the complex process of using data.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="312-jindoruntime">3.1.2 JindoRuntime<a href="#312-jindoruntime" class="hash-link" aria-label="3.1.2 JindoRuntime的直接链接" title="3.1.2 JindoRuntime的直接链接">​</a></h4>
<p>JindoRuntime [2] is a distributed cache runtime implementation of Fluid based on the <a href="https://www.alibabacloud.com/help/doc-detail/199488.htm?spm=a2c65.11461447.0.0.3e0250edNCbWGb" target="_blank" rel="noopener noreferrer">JindoFS</a> distributed cache acceleration engine. JindoFS is an engine for optimizing big data storage, which is developed by the Alibaba Cloud EMR Team. It is fully compatible with the Hadoop file system interface and brings clients more flexible and efficient computing and storage solutions. JindoRuntime uses JindoFS&#x27;s cache mode to access and cache remote files. It supports access and cache acceleration for various storage products such as OSS, HDFS, and AWS S3. The process of using and deploying JindoRuntime on Fluid is simple. It is compatible with the native Kubernetes environment and provides out-of-the-box features. It deeply integrates the features of OSS and optimizes performance with the Native framework. It also supports on-cloud data security features, such as password-free and checksum verification.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="32-reasons-for-choosing-jindoruntime-based-fluid">3.2 Reasons for Choosing JindoRuntime-Based Fluid<a href="#32-reasons-for-choosing-jindoruntime-based-fluid" class="hash-link" aria-label="3.2 Reasons for Choosing JindoRuntime-Based Fluid的直接链接" title="3.2 Reasons for Choosing JindoRuntime-Based Fluid的直接链接">​</a></h3>
<ol>
<li>
<p>Fluid can orchestrate datasets in Kubernetes clusters to achieve the same placement of data and computing. It can also provide interfaces based on Persistent Volume Claim to connect to applications on Kubernetes seamlessly. At the same time, JindoRuntime provides acceleration for accessing and caching data on HDFS. With the POSIX file system interface of FUSE, we can easily work with the massive files on HDFS just like a local disk. Deep learning training tools, such as PyTorch can read the training data using the POSIX file interface.</p>
</li>
<li>
<p>JindoRuntime has made specified optimizations on data organization, management, and access performance of small files for the performance problem of remote data access of large amounts of small files. JindoRuntime can provide efficient access performance for small files, which is much better than accessing HDFS directly.</p>
</li>
<li>
<p>It provides distributed and hierarchical caching of metadata and data and efficient retrieval of small files.</p>
</li>
<li>
<p>It provides a data prefetching mechanism to avoid data access competition caused by pulling data during the training process.</p>
</li>
<li>
<p>It organizes file data with slab allocation and utilizes cache space efficiently.</p>
</li>
<li>
<p>With the data perception and scheduling capability of Fluid, users can place tasks in nodes with cached data without knowing the information of cached nodes. This maximizes the advantages of data access performance.</p>
</li>
<li>
<p>It provides different cache policies and storage methods for small and large files. It has good adaptability to AI training scenarios with small files, and no configuration is required.</p>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="33-practices">3.3 Practices<a href="#33-practices" class="hash-link" aria-label="3.3 Practices的直接链接" title="3.3 Practices的直接链接">​</a></h3>
<ol>
<li>
<p><strong>Select Appropriate Cache Nodes:</strong> With JindoRuntime, we can enjoy better local data performance. In production, we have found that using all cache nodes for storage does not necessarily bring better performance. The reason is that the disk and network I/O performance of some nodes is not very good. We need to select cache nodes with large-capacity disks and better networks to solve this problem. Fluid supports the schedulability of datasets, namely the schedulability of cache nodes. We schedule cache nodes of datasets by specifying the nodeAffinity of datasets to ensure that cache nodes provide cache services efficiently.</p>
</li>
<li>
<p><strong>Specify the Scheduling Policy for Master Nodes:</strong> JindoRuntime consists of three parts: master, worker, and fuse. Master is the head of clusters and is responsible for the management of metadata and cluster cache. Therefore, the master node has strong reliability and a fast speed of failure recovery. During the production, we found that a single master has strong reliability and a fast speed of failure recovery. An important factor that affects the stability of master nodes is the stability of the host. For example, full disks and communication failure of the host will affect the stability of master nodes. Based on this, we use nodeselector for master nodes to select the host with better performance as the master container environment to ensure the stability of the master environment.</p>
</li>
<li>
<p><strong>Prefetch the Data Regularly:</strong> An important step before training is to prefetch the metadata and data. Fluid provides metadata and data caching in the form of CRD. Before training, the metadata and data of training files are cached locally, which can accelerate the training substantially. However, the training files stored on HDFS are updated once a day, so the data prefetching process needs to be performed periodically and regularly. Based on the CRD of dataload, we use cronJob to perform periodic scheduling. By doing so, the metadata and data can be prepared before training to ensure efficient training. Of course, JindoRuntime also supports incremental synchronization, so only files that are changed need to be updated each time. This speeds up data prefetching substantially.</p>
</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="34-performance-test-scheme">3.4 Performance Test Scheme<a href="#34-performance-test-scheme" class="hash-link" aria-label="3.4 Performance Test Scheme的直接链接" title="3.4 Performance Test Scheme的直接链接">​</a></h2>
<p>We have verified the overall effect of the solutions above from different aspects, such as stability and performance. Then, we focus on the performance test scheme. The training models are all video understanding models based on mmaction and adopt the rawframes_train method. It is a test of the training dataset with 4,000,000 pictures. The data is obtained from 400,000 videos extracted from real business scenarios with 10 frames per scenario. Due to the different video definitions, the size of each picture ranges from a few KB to a dozen MB. The total size is about 780 GB, with each cache node providing 300 GB of cache space. In our experience, model convergence is typically achieved around 50 epochs.</p>
<p>When we adjust the data volume of the tested video to 1,000,000, the total data size is 2 TB. Due to the massive data volume and high latency, the HDFS interface mode could not work at all, while Fluid with JindoRuntime could meet the requirements of the business.</p>
<p>Fluid JindoRuntime is used to prefetch data and train models.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="35-results-of-performance-testing">3.5 Results of Performance Testing<a href="#35-results-of-performance-testing" class="hash-link" aria-label="3.5 Results of Performance Testing的直接链接" title="3.5 Results of Performance Testing的直接链接">​</a></h2>
<p>Combined with the solution of Fluid + JindoRuntime, we have achieved an improvement in the training speed after data prefetching. As shown in the figure below, in the scenario of 3 nodes and 12 GPUs, the test of reading data through the HDFS interface is often interrupted due to problems, such as poor network communication. This leads to test failure. After adding exception handling, the waiting time between workers becomes longer. As a result, the increasement of GPUs slows down training rather than speeds up it. The overall training speed is virtually the same in the scenario of 1 node and 8 GPUs as well as 3 nodes and 12 GPUs, and the computing resources are scaled out. Through the new scheme, we found that compared with the HDFS interface, the scenario of 1 node and 4 GPUs can be accelerated by 5 times, 2 nodes and 8 GPUs by 9 times, and 3 nodes and 12 GPUs by 18 times.</p>
<p><img decoding="async" loading="lazy" alt="result-1" src="/zh/assets/images/weibo-res-1-705dc55710ef78c31190ae6f1cb7ec33.png" width="529" height="297" class="img_ev3q"></p>
<p>Since speed and stability of training are guaranteed, the model’s end-to-end training time has also been reduced from 389 hours (16 days) to 16 hours.</p>
<p><img decoding="async" loading="lazy" alt="result-1" src="/zh/assets/images/weibo-res-2-5763966955f1fdb11eec5c3c458211bd.png" width="574" height="314" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-summary">4. Summary<a href="#4-summary" class="hash-link" aria-label="4. Summary的直接链接" title="4. Summary的直接链接">​</a></h2>
<p>After the integration of Fluid and JindoRuntime, the performance and stability of model training in small file scenarios are improved significantly. In the distributed training of multiple nodes and multiple GPUs, the model training speed can be increased by 18 times. Training that used to take two weeks and now only takes 16 hours. Shorter time for training and less pressure on HDFS also improve the stability of training tasks, with the success rate increasing from 37.1% to 98.3%. The amount of data in our production environment is currently 4 TB and will continue to grow with continuous iteration.</p>
<p>Weibo AI training scenarios have high requirements on data reading performance, and a large number of small files are also very sensitive to access latency. The caching capability of JindoRuntime can accelerate the caching of data in big data storage systems effectively. It provides stable and reliable data access performance with high throughput and low latency. At the same time, it can relieve the pressure on the backend storage system and ensure the stability of the backend storage. Optimization of small file reading and caching for specific scenarios can relieve the I/O pressure on HDFS clusters and improve training efficiency.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="5-outlook">5. Outlook<a href="#5-outlook" class="hash-link" aria-label="5. Outlook的直接链接" title="5. Outlook的直接链接">​</a></h2>
<p>Currently, Fluid + JindoRuntime is more of a trump card that accelerates small filescenarios, rather than a conventional weapon that accelerates and optimizes all data sets. We hope that flexible data acceleration can be used as the differentiation capability of the Weibo deep learning platform to improve the overall training task speed and the utilization of computing resources. We also hope to help the community continue to evolve and help more developers. Specifically:</p>
<ul>
<li>Support scheduled tasks and dynamic scale-in and scale-out</li>
<li>Improve performance of data prefetching, provide metadata backup mechanism, and realize the rebuilding of data sets</li>
<li>Provide a performance monitoring console</li>
<li>Support high availability for Runtime metadata and image upgrades</li>
<li>Support full lifecycle management of multiple datasets in a scale Kubernetes cluster</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="acknowledgement">Acknowledgement<a href="#acknowledgement" class="hash-link" aria-label="Acknowledgement的直接链接" title="Acknowledgement的直接链接">​</a></h2>
<p>Thanks to Chenshan and Yangli of the Alibaba Cloud JindoFS Team and Cheyang of the Container Team for all their help during the designing and optimization process. They have endowed existing applications with data acceleration capabilities without any application transformation. They have also provided timely and professional support for requirements and problems in the testing and production environments.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="references">References<a href="#references" class="hash-link" aria-label="References的直接链接" title="References的直接链接">​</a></h2>
<p>For more information about Fluid and JindoFS, please refer to the links below:</p>
<ul>
<li>
<p>[1] <a href="https://github.com/fluid-cloudnative/fluid" target="_blank" rel="noopener noreferrer">Fluid</a></p>
</li>
<li>
<p>[2] <a href="https://github.com/aliyun/alibabacloud-jindodata" target="_blank" rel="noopener noreferrer">JindoFS</a></p>
</li>
</ul>
<p>Click the following link for our project on GitHub!</p>
<ul>
<li><a href="https://github.com/fluid-cloudnative/fluid" target="_blank" rel="noopener noreferrer">https://github.com/fluid-cloudnative/fluid</a></li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/fluid-cloudnative/fluid-cloudnative.github.io/tree/master/versioned_docs/version-v1.0.0/case-study/weibo-case-study.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>编辑此页</a></div><div class="col lastUpdated_vwxv"><span class="theme-last-updated">最后<!-- -->由 <b>chenqiming</b> <!-- -->于 <b><time datetime="2024-04-17T09:10:55.000Z">2024年4月17日</time></b> <!-- -->更新</span></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="文件选项卡"><a class="pagination-nav__link pagination-nav__link--prev" href="/zh/docs/case-study/alibaba-case-study"><div class="pagination-nav__sublabel">上一页</div><div class="pagination-nav__label">Alibaba&#x27;s Case Study</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/zh/docs/case-study/metabit-trading-case-study"><div class="pagination-nav__sublabel">下一页</div><div class="pagination-nav__label">Metabit Trading&#x27;s Case Study</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#1-background" class="table-of-contents__link toc-highlight">1. Background</a></li><li><a href="#2-challenges-of-training-large-scale-deep-learning-models" class="table-of-contents__link toc-highlight">2. Challenges of Training Large-Scale Deep Learning Models</a></li><li><a href="#3-fluid--jindoruntime-provide-efficient-support-for-weibos-machine-learning-platform" class="table-of-contents__link toc-highlight">3. Fluid + JindoRuntime Provide Efficient Support for Weibo&#39;s Machine Learning Platform</a><ul><li><a href="#31-an-introduction-to-architecture-components" class="table-of-contents__link toc-highlight">3.1 An Introduction to Architecture Components</a></li><li><a href="#32-reasons-for-choosing-jindoruntime-based-fluid" class="table-of-contents__link toc-highlight">3.2 Reasons for Choosing JindoRuntime-Based Fluid</a></li><li><a href="#33-practices" class="table-of-contents__link toc-highlight">3.3 Practices</a></li></ul></li><li><a href="#34-performance-test-scheme" class="table-of-contents__link toc-highlight">3.4 Performance Test Scheme</a></li><li><a href="#35-results-of-performance-testing" class="table-of-contents__link toc-highlight">3.5 Results of Performance Testing</a></li><li><a href="#4-summary" class="table-of-contents__link toc-highlight">4. Summary</a></li><li><a href="#5-outlook" class="table-of-contents__link toc-highlight">5. Outlook</a></li><li><a href="#acknowledgement" class="table-of-contents__link toc-highlight">Acknowledgement</a></li><li><a href="#references" class="table-of-contents__link toc-highlight">References</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">文档</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/zh/docs">教程</a></li></ul></div><div class="col footer__col"><div class="footer__title">社区</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://app.slack.com/client/T08PSQ7BQ/C02ADG209SP" target="_blank" rel="noopener noreferrer" class="footer__link-item">CNCF Slack (#fluid channel)<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/zh/community/meeting_schedule">钉钉群 (群号: 32850151)</a></li><li class="footer__item"><a class="footer__link-item" href="/zh/community/meeting_schedule">周会</a></li><li class="footer__item"><a href="https://github.com/fluid-cloudnative/fluid/blob/master/README.md#community" target="_blank" rel="noopener noreferrer" class="footer__link-item">微信群<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">更多</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/fluid-cloudnative/fluid" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 The Fluid Authors. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our Trademark Usage page: https://www.linuxfoundation.org/trademark-usage</div></div></div></footer></div>
</body>
</html>