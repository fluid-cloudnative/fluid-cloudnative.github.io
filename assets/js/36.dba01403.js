(window.webpackJsonp=window.webpackJsonp||[]).push([[36],{392:function(t,a,s){"use strict";s.r(a);var e=s(19),n=Object(e.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"demo-speed-up-accessing-hdfs-client-files"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#demo-speed-up-accessing-hdfs-client-files"}},[t._v("#")]),t._v(" DEMO - Speed Up Accessing HDFS Client Files")]),t._v(" "),a("p",[t._v("This demo introduces how to use HDFS Client to access remote files by "),a("a",{attrs:{href:"https://www.alluxio.io",target:"_blank",rel:"noopener noreferrer"}},[t._v("Alluxio"),a("OutboundLink")],1),t._v(" in Fluid, and it can accelerate the access of remote files powered by the file cache ability of Alluxio.")]),t._v(" "),a("h2",{attrs:{id:"prerequisites"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#prerequisites"}},[t._v("#")]),t._v(" Prerequisites")]),t._v(" "),a("p",[t._v("Before everything we are going to do, please refer to "),a("RouterLink",{attrs:{to:"/guide/get_started.html"}},[t._v("Installation Guide")]),t._v(" to install Fluid on your Kubernetes Cluster, and make sure all the components used by Fluid are ready like this:")],1),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("$ kubectl get pod "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-n")]),t._v(" fluid-system\nNAME                                  READY   STATUS    RESTARTS   AGE\nalluxioruntime-controller-5b64fdbbb-84pc6   "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("/1     Running   "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("          8h\ncsi-nodeplugin-fluid-fwgjh                  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("/2     Running   "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("          8h\ncsi-nodeplugin-fluid-ll8bq                  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("/2     Running   "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("          8h\ndataset-controller-5b7848dbbb-n44dj         "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("/1     Running   "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("          8h\n")])])]),a("h2",{attrs:{id:"set-up-workspace"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#set-up-workspace"}},[t._v("#")]),t._v(" Set Up Workspace")]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("$ "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("mkdir")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("any-path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("/hdfs\n$ "),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("cd")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("any-path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("/hdfs\n")])])]),a("h2",{attrs:{id:"install-resources-to-kubernetes"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#install-resources-to-kubernetes"}},[t._v("#")]),t._v(" Install Resources to Kubernetes")]),t._v(" "),a("p",[a("strong",[t._v("Check the "),a("code",[t._v("Dataset")]),t._v(" object to be created")])]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("$ cat"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<<")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("EOF"),a("span",{pre:!0,attrs:{class:"token bash punctuation"}},[t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("dataset.yaml")]),t._v("\napiVersion: data.fluid.io/v1alpha1\nkind: Dataset\nmetadata:\n  name: hadoop\nspec:\n  mounts:\n    - mountPoint: https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/core/current/\n      name: hadoop\nEOF")]),t._v("\n")])])]),a("p",[t._v("Here, we'd like to create a resource object with kind "),a("code",[t._v("Dataset")]),t._v(". "),a("code",[t._v("Dataset")]),t._v(" is a Custom Resource Definition(CRD) defined by Fluid and used to tell Fluid where to find all the data you'd like to access.\nUnder the hood, Fluid uses Alluxio to do some mount operations, so "),a("code",[t._v("mountPoint")]),t._v(" property can be any legal UFS path acknowledged by Alluxio. Here, we use "),a("a",{attrs:{href:"https://docs.alluxio.io/os/user/stable/en/ufs/WEB.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("WebUFS"),a("OutboundLink")],1),t._v(" for its simplicity.")]),t._v(" "),a("p",[a("strong",[t._v("Create a Dataset resource object")])]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("$ kubectl create "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-f")]),t._v(" dataset.yaml\ndataset.data.fluid.io/hadoop created\n")])])]),a("p",[a("strong",[t._v("Inspect the status of the Dataset resource object")])]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("$ kubectl get dataset hadoop\nNAME     UFS TOTAL SIZE   CACHED   CACHE CAPACITY   CACHED PERCENTAGE   PHASE      AGE\nhadoop                                                                  NotBound   1m\n")])])]),a("p",[t._v("As shown above, the value of attribute "),a("code",[t._v("phase")]),t._v(" in "),a("code",[t._v("status")]),t._v(" is "),a("code",[t._v("NotBound")]),t._v(", which means that the "),a("code",[t._v("Dataset")]),t._v(" resource object is not binded with any "),a("code",[t._v("AlluxioRuntime")]),t._v(" resource object currently. Next, we will create an "),a("code",[t._v("AlluxioRuntime")]),t._v(" resource object.")]),t._v(" "),a("p",[a("strong",[t._v("Inspect the AlluxioRuntime resource object to be created")])]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("$ cat"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<<")]),t._v("EOF "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("runtime.yaml\napiVersion: data.fluid.io/v1alpha1\nkind: AlluxioRuntime\nmetadata:\n  name: hadoop\nspec:\n  replicas: "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n  tieredstore:\n    levels:\n      - mediumtype: MEM\n        path: /dev/shm\n        quota: 2Gi\n        high: "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0.95"')]),t._v("\n        low: "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0.7"')]),t._v("\n")])])]),a("p",[a("strong",[t._v("Create an AlluxioRuntime resource object")])]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("$ kubectl apply "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-f")]),t._v(" runtime.yaml\nalluxioruntime.data.fluid.io/hadoop created\n")])])]),a("p",[a("strong",[t._v("Inspect the status of the AlluxioRuntime resource object")])]),t._v(" "),a("p",[a("code",[t._v("AlluxioRuntime")]),t._v(" is a CRD defined by another Fluid. An "),a("code",[t._v("AlluxioRuntime")]),t._v(" resource object describes configuration information needed by running an Alluxio instance in a Kubernetes cluster.")]),t._v(" "),a("p",[t._v("Wait until each component in the AlluxioRuntime resource object starts successfully, and you will see status like the following:")]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("$ hdfs kubectl get pods\nNAME                            READY   STATUS    RESTARTS   AGE\nhadoop-fuse-749fs               "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("/1     Running   "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("          64s\nhadoop-fuse-khdrb               "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("/1     Running   "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("          64s\nhadoop-master-0                 "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("/2     Running   "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("          106s\nhadoop-worker-cn9fg             "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("/2     Running   "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("          64s\nhadoop-worker-tlldq             "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("/2     Running   "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("          64s\n")])])]),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("$ kubectl get alluxioruntime hadoop\nNAME     MASTER PHASE   WORKER PHASE   FUSE PHASE   AGE\nhadoop   Ready          Ready          Ready        116s\n")])])]),a("p",[t._v("Inspect the status of the Dataset again, and you will find that it has been binded with AlluxioRuntime.")]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("$ kubectl get dataset hadoop\nNAME     UFS TOTAL SIZE   CACHED   CACHE CAPACITY   CACHED PERCENTAGE   PHASE   AGE\nhadoop   "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("390")]),t._v(".2MiB         0B       4GiB             "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("%                  Bound   55m\n")])])]),a("p",[t._v("When the Dataset resource object is prepared, i.e. has been binded with an Alluxio instance, PV and PVC related to the resource object has been generated by Fluid. Via the PVC, applications are able to mount remote files in Pod, and enable remote file access by mounting directories.")]),t._v(" "),a("h2",{attrs:{id:"access-files-through-hdfs-client"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#access-files-through-hdfs-client"}},[t._v("#")]),t._v(" Access files through HDFS Client")]),t._v(" "),a("p",[a("strong",[t._v("Prepare test program")])]),t._v(" "),a("p",[t._v("This example uses HDFS Java Client to access files, and the following dependencies need to be introduced when writing client code")]),t._v(" "),a("div",{staticClass:"language-xml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-xml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.hadoop"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("hadoop-client"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("${hadoop.version}"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.hadoop"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("hadoop-hdfs"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("${hadoop.version}"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.alluxio"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("alluxio-core-client"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("${alluxio.version}"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("type")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("pom"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("type")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.alluxio"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("alluxio-core-client-hdfs"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("${alluxio.version}"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),a("p",[t._v("At the same time, add the configuration of alluxio in core-site.xml. For details and troubleshooting, please refer to "),a("a",{attrs:{href:"https://docs.alluxio.io/os/user/stable/en/compute/Hadoop-MapReduce.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("Running Hadoop MapReduce on Alluxio"),a("OutboundLink")],1),t._v("。")]),t._v(" "),a("div",{staticClass:"language-xml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-xml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("fs.alluxio.impl"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("alluxio.hadoop.FileSystem"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("description")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("The Alluxio FileSystem"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("description")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),a("p",[t._v("When accessing files through the HDFS client, you need to specify the HDFS server address")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("final")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[t._v("HDFS_URL")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"alluxio://hadoop-master-0.default.svc.cluster.local:"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getenv")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"HADOOP_PORT"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/hadoop"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Configuration")]),t._v(" conf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Configuration")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("FileSystem")]),t._v(" fs "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("FileSystem")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token constant"}},[t._v("URI")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("create")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token constant"}},[t._v("HDFS_URL")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" conf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[t._v("Note that the HDFS_URL domain name rule here is:")]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("alluxio://"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("HCFS URL"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("/"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("DATASET_NAME"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[t._v("Where DATASET_NAME is the name of the Dataset created earlier, in this case it is hadoop. The Endpoint can be obtained through the following command to obtain the HCFS (Hadoop Compatible FileSystem) URL")]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v(" kubectl get datasets.data.fluid.io "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-owide")]),t._v("\nNAME    UFS TOTAL SIZE   CACHED   CACHE CAPACITY   CACHED PERCENTAGE   PHASE   HCFS URL                                 AGE\nhbase   "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("443")]),t._v(".49MiB        "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(".00B    "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(".00GiB          "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0")]),t._v("%                Bound   alluxio://hbase-master-0.default:19998   97s\n")])])]),a("p",[t._v("For the complete test code, please refer to "),a("a",{attrs:{href:"../../../samples/hdfs"}},[t._v("samples/hdfs")]),t._v(". We made the test code into a mirror to facilitate the next test. The mirror address is registry.cn-hangzhou.aliyuncs.com/qiulingwei/fluid-hdfs-demo:1.2.0")]),t._v(" "),a("p",[a("strong",[t._v("查看待创建的测试作业")])]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("$ cat"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<<")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("EOF"),a("span",{pre:!0,attrs:{class:"token bash punctuation"}},[t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("app.yaml")]),t._v('\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: fluid-hdfs-demo\nspec:\n  template:\n    spec:\n      restartPolicy: OnFailure\n      containers:\n        - name: fluid-hdfs-demo\n          image: registry.cn-hangzhou.aliyuncs.com/qiulingwei/fluid-hdfs-demo:1.3.0\n          imagePullPolicy: Always\n          env:\n          - name: HADOOP_PORT\n            value: "19998"\nEOF')]),t._v("\n")])])]),a("p",[t._v("Here, you need to replace 19998 in the environment variable with the actual port in the HCFS (Hadoop Compatible FileSystem) URL just queried")]),t._v(" "),a("p",[a("strong",[t._v("启动测试作业")])]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("$ kubectl apply "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-f")]),t._v(" app.yaml\njob.batch/fluid-hdfs-demo created\n")])])]),a("p",[t._v("In the test program, we first traverse the Dataset to see which files are there, and then copy these files to the local to see the acceleration effect of accessing remote files.")]),t._v(" "),a("p",[t._v("Wait for a period of time, after the job is completed, the running status of the job can be viewed by the following command:")]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("$ kubectl get pods\nNAME                            READY   STATUS      RESTARTS   AGE\nfluid-hdfs-demo-8q9b7           "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("/1     Completed   "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("          14m\n")])])]),a("p",[a("strong",[t._v("查看任务执行时间")])]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("$ kubectl logs fluid-hdfs-demo-8q9b7\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## RELEASENOTES.md")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## hadoop-3.1.3-src.tar.gz")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## CHANGES.md")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## hadoop-3.1.3-site.tar.gz")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## hadoop-3.1.3-rat.txt")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## hadoop-3.1.3.tar.gz")]),t._v("\ncopy directory cost:67520ms\n")])])]),a("p",[t._v("It took more than 67 seconds to execute the job for the first time.")]),t._v(" "),a("p",[a("strong",[t._v("Check status of the "),a("code",[t._v("Dataset")]),t._v(" object")])]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("$ kubectl get dataset hadoop\nNAME     UFS TOTAL SIZE   CACHED     CACHE CAPACITY   CACHED PERCENTAGE   PHASE   AGE\nhadoop   "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("390")]),t._v(".2MiB         "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("388")]),t._v(".4MiB   4GiB             "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("99")]),t._v("%                 Bound   88m\n")])])]),a("p",[t._v("We can see that all remote files have been cached in Alluxio.")]),t._v(" "),a("p",[a("strong",[t._v("Launch a test job again")])]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("$ kubectl delete "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-f")]),t._v(" app.yaml\n$ kubectl create "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-f")]),t._v(" app.yaml\n")])])]),a("p",[t._v("Since the remote files have been cached, the time consumption of this job is greatly reduced.")]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("$ kubectl logs fluid-hdfs-demo-pxt45\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## RELEASENOTES.md")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## hadoop-3.1.3-src.tar.gz")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## CHANGES.md")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## hadoop-3.1.3-site.tar.gz")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## hadoop-3.1.3-rat.txt")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## hadoop-3.1.3.tar.gz")]),t._v("\ncopy directory cost:1300ms\n")])])]),a("p",[t._v("We repeat the job, taking only 1.3 seconds to access the same file.")]),t._v(" "),a("p",[t._v("This great acceleration effect is attributed to the powerful caching capability provided by Alluxio. This caching capability means that as long as you access a remote file once, the file will be cached in Alluxio,and all your subsequent repeated accesses no longer require remote file reading, but obtain data directly from Alluxio, so it is not difficult to explain the acceleration of data access.")]),t._v(" "),a("h2",{attrs:{id:"clean-up-environment"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#clean-up-environment"}},[t._v("#")]),t._v(" Clean Up Environment")]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("$ kubectl delete "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-f")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(".")]),t._v("\n")])])])])}),[],!1,null,null,null);a.default=n.exports}}]);